# Default values for spark.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: ranchercharts/spark
  tag: v2.3.1
  pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

service:
  type: NodePort

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    memory: 1408Mi
  requests:
    cpu: "1"
    memory: 1Gi

nodeSelector: {}

tolerations: []

affinity: {}

javaOpts:
  instances: 5
  # e.g, "https://github.com/JWebDev/spark/raw/master/spark-examples_2.11-2.3.1.jar,https://github.com/JWebDev/spark/raw/master/spark-examples_2.11-2.3.1.jar"
  remoteJars: "https://github.com/JWebDev/spark/raw/master/spark-examples_2.11-2.3.1.jar,https://github.com/JWebDev/spark/raw/master/spark-examples_2.11-2.3.1.jar"

  # More spark environment configurations 
  # https://spark.apache.org/docs/2.3.0/running-on-kubernetes.html#configuration
  env:
    # SPARK_JAVA_OPT_16: -Dspark.kubernetes.allocation.batch.delay=1s

## If RBAC is enabled on the cluster, the Kafka init container needs a service account
## with permissisions sufficient to apply pod labels
rbacEnable: true
